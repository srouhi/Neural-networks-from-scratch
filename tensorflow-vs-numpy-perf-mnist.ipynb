{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from PIL import Image as PILImage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensorflow is installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"\\nTensorflow is installed.\")\n",
    "except ImportError as e:\n",
    "    print(\"Tensorflow not installed, please install it using 'pip install tensorflow.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the element-wise product of two vectors using Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.005423500027973205 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size = (50000,)\n",
    "u = tf.random.uniform(size)\n",
    "v = tf.random.uniform(size)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "tf.math.multiply(u, v)\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the element-wise product of two vectors using a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0014513000496663153 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size = (5000,)\n",
    "pre_a = np.zeros(size)\n",
    "pre_b = np.zeros(size)\n",
    "\n",
    "a = np.random.uniform(pre_a)\n",
    "b = np.random.uniform(pre_b)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "result = np.zeros(size)\n",
    "\n",
    "for i in range(size[0]):\n",
    "    result= a[i]*b[i]\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "execution_time=end_time-start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that using Tensorflow the operation is faster around 4 x 10^-3 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define 2x2 matrics A and B and compute AB+3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  8]\n",
      " [47 17]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A = tf.constant([[1,2],[3,4]])\n",
    "B = tf.constant([[4,1],[5,2]])\n",
    "\n",
    "#AB\n",
    "AB = tf.matmul(A,B)\n",
    "#3B\n",
    "ThreeB = tf.scalar_mul(3, B)\n",
    "#AB+3B\n",
    "final = tf.add(AB, ThreeB)\n",
    "print(np.array(final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(A[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the value in first row and 2nd column of A is 2. we put 0 first for row, because 0 is the first index and represent row 1 and 1 for column which is 2nd index or column 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### its convenient to convert tensor objects to NumPy arrays and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(A.numpy()) # convert tensor to numpy array\n",
    "\n",
    "A_r1 = A.numpy()[0] # first row of A as numpy array\n",
    "A_r1 = tf.constant(A_r1) # convert numpy array to tensor\n",
    "\n",
    "print(A_r1) # convert numpy array to tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [5 2]]\n"
     ]
    }
   ],
   "source": [
    "print(B.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "#### load the MNIST dataset, it contains 70,000 samples of handwritten digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() # load dataset and split into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the first image. Use Python and the `train_labels` to print a message stating the digit in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#display first image\n",
    "image1 = np.array(train_images[0])\n",
    "plt.imshow(image1)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#print the message\n",
    "print(train_labels[0])\n",
    "#it's 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Observations:\n",
    "- there are 2^32 = 4,294,967,296  floating point numbers in a 32-bit system.  \n",
    "- while in normalized 32-bit system there are 2^32-2^24 ~ 4.28 billion numbers.   \n",
    "- decimal precision of a 32-bit system is approximately 7 decimal digits. (24 total bits * (log10(2)~ 0.301) ~ 7.22) example: 123.4567\n",
    "- decimal precision of a 32-bit floating point number in the range $0$ to $1$ is also about 7 decimal digits. (because in ormalized form we still have 24 bits) example: 0.1234567  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "#### Normalize the training and testing datasets to reshape the images to be arrays of size `(784,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = tf.reshape(train_images / 255.0, (-1, 784))\n",
    "test_images = tf.reshape(test_images / 255.0, (-1, 784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the training and testing labels to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "#print(train_labels.shape)\n",
    "#print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and Training Our Model\n",
    "Defining a feedforward neural network using Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shagh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify our loss function and *optimizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.MSE\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy']) # initialize model weights and compile model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the model to the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000,), dtype=float32, numpy=\n",
       "array([0.08998682, 0.08997376, 0.08997457, ..., 0.08997384, 0.09000552,\n",
       "       0.09002867], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lables = model(train_images)\n",
    "loss_function(train_labels, pred_lables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.1277 - loss: 0.0900\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1118 - loss: 0.0900\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1113 - loss: 0.0900\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1133 - loss: 0.0900\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1123 - loss: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2e0177a9bd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,\n",
    "          train_labels, \n",
    "          epochs=5, \n",
    "          batch_size=32) # train model on training data for 5 epochs with batch size of 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Fashion MNIST dataset & Display the first 5 images and print their labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "#display first 5 images and their lables\n",
    "for i in range(5):\n",
    "    image = np.array(train_images[i])\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the training and testing data: normalize and reshape the images and convert the labels to categorical data. Then define and train a model with $784\\times 128\\times 64\\times 32\\times 10$ architecture \n",
    "Have the ReLU activation function in every layer except the last. For the final layer, use softmax for the activation function. Use stochastic gradient descent to train the model and mean squared error for its loss function. Train until your model has at least $90\\%$ accuracy on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_images = tf.reshape(train_images/255.0,(-1, 784))\n",
    "print(train_images.shape)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shagh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "loss_function = tf.keras.losses.MSE\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy']) # initialize model weights and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.0165\n",
      "Epoch 2/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.0162\n",
      "Epoch 3/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8917 - loss: 0.0165\n",
      "Epoch 4/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.0164\n",
      "Epoch 5/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.0162\n",
      "Epoch 6/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.0163\n",
      "Epoch 7/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.0162\n",
      "Epoch 8/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.0161\n",
      "Epoch 9/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.0162\n",
      "Epoch 10/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.0163\n",
      "Epoch 11/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.0159\n",
      "Epoch 12/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.0162\n",
      "Epoch 13/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.0160\n",
      "Epoch 14/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.0158\n",
      "Epoch 15/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.0159\n",
      "Epoch 16/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.0157\n",
      "Epoch 17/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.0159\n",
      "Epoch 18/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.0162\n",
      "Epoch 19/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.0161\n",
      "Epoch 20/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.0162\n",
      "Epoch 21/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.0160\n",
      "Epoch 22/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.0161\n",
      "Epoch 23/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.0159\n",
      "Epoch 24/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.0159\n",
      "Epoch 25/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.0159\n",
      "Epoch 26/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.0160\n",
      "Epoch 27/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.0159\n",
      "Epoch 28/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.0159\n",
      "Epoch 29/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 0.0160\n",
      "Epoch 30/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.0157\n",
      "Epoch 31/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.0158\n",
      "Epoch 32/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.0157\n",
      "Epoch 33/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.0158\n",
      "Epoch 34/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.0156\n",
      "Epoch 35/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.0158\n",
      "Epoch 36/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.0157\n",
      "Epoch 37/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.0154\n",
      "Epoch 38/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.0158\n",
      "Epoch 39/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.0158\n",
      "Epoch 40/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.0156\n",
      "Epoch 41/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.0156\n",
      "Epoch 42/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.0157\n",
      "Epoch 43/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.0157\n",
      "Epoch 44/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.0154\n",
      "Epoch 45/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.0156\n",
      "Epoch 46/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.0155\n",
      "Epoch 47/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 0.0158\n",
      "Epoch 48/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.0155\n",
      "Epoch 49/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.0152\n",
      "Epoch 50/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.0157\n",
      "Epoch 51/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.0156\n",
      "Epoch 52/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.0154\n",
      "Epoch 53/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.0154\n",
      "Epoch 54/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.0154\n",
      "Epoch 55/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.0152\n",
      "Epoch 56/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.0155\n",
      "Epoch 57/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.0156\n",
      "Epoch 58/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.0152\n",
      "Epoch 59/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.0155\n",
      "Epoch 60/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.0153\n",
      "Epoch 61/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.0157\n",
      "Epoch 62/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.0153\n",
      "Epoch 63/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.0157\n",
      "Epoch 64/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.0153\n",
      "Epoch 65/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.0153\n",
      "Epoch 66/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.0151\n",
      "Epoch 67/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.0153\n",
      "Epoch 68/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.0154\n",
      "Epoch 69/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.0151\n",
      "Epoch 70/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.0152\n",
      "Epoch 71/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.0152\n",
      "Epoch 72/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.0152\n",
      "Epoch 73/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.0150\n",
      "Epoch 74/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9028 - loss: 0.0150\n",
      "Epoch 75/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.0152\n",
      "Epoch 76/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.0152\n",
      "Epoch 77/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.0150\n",
      "Epoch 78/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.0150\n",
      "Epoch 79/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.0149\n",
      "Epoch 80/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.0150\n",
      "Epoch 81/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.0151\n",
      "Epoch 82/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.0148\n",
      "Epoch 83/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.0150\n",
      "Epoch 84/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.0148\n",
      "Epoch 85/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.0149\n",
      "Epoch 86/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.0150\n",
      "Epoch 87/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.0148\n",
      "Epoch 88/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.0150\n",
      "Epoch 89/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.0148\n",
      "Epoch 90/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.0147\n",
      "Epoch 91/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.0150\n",
      "Epoch 92/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.0147\n",
      "Epoch 93/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.0148\n",
      "Epoch 94/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.0148\n",
      "Epoch 95/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.0152\n",
      "Epoch 96/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.0147\n",
      "Epoch 97/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.0147\n",
      "Epoch 98/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.0148\n",
      "Epoch 99/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.0148\n",
      "Epoch 100/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.0147\n",
      "Epoch 101/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.0147\n",
      "Epoch 102/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.0145\n",
      "Epoch 103/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.0153\n",
      "Epoch 104/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.0146\n",
      "Epoch 105/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.0146\n",
      "Epoch 106/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.0148\n",
      "Epoch 107/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.0147\n",
      "Epoch 108/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.0148\n",
      "Epoch 109/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9015 - loss: 0.0150\n",
      "Epoch 110/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.0147\n",
      "Epoch 111/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.0146\n",
      "Epoch 112/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.0145\n",
      "Epoch 113/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.0147\n",
      "Epoch 114/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.0143\n",
      "Epoch 115/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.0143\n",
      "Epoch 116/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.0144\n",
      "Epoch 117/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.0143\n",
      "Epoch 118/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.0145\n",
      "Epoch 119/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.0149\n",
      "Epoch 120/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.0143\n",
      "Epoch 121/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.0146\n",
      "Epoch 122/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.0147\n",
      "Epoch 123/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.0147\n",
      "Epoch 124/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.0144\n",
      "Epoch 125/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.0142\n",
      "Epoch 126/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.0145\n",
      "Epoch 127/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.0144\n",
      "Epoch 128/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.0142\n",
      "Epoch 129/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.0144\n",
      "Epoch 130/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.0142\n",
      "Epoch 131/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.0145\n",
      "Epoch 132/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.0145\n",
      "Epoch 133/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.0147\n",
      "Epoch 134/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.0142\n",
      "Epoch 135/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9052 - loss: 0.0147\n",
      "Epoch 136/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.0144\n",
      "Epoch 137/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.0144\n",
      "Epoch 138/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.0143\n",
      "Epoch 139/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.0139\n",
      "Epoch 140/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.0143\n",
      "Epoch 141/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.0143\n",
      "Epoch 142/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.0143\n",
      "Epoch 143/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.0140\n",
      "Epoch 144/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.0142\n",
      "Epoch 145/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.0142\n",
      "Epoch 146/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.0142\n",
      "Epoch 147/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.0140\n",
      "Epoch 148/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.0140\n",
      "Epoch 149/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.0143\n",
      "Epoch 150/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.0141\n",
      "Epoch 151/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.0139\n",
      "Epoch 152/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.0140\n",
      "Epoch 153/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.0140\n",
      "Epoch 154/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.0142\n",
      "Epoch 155/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.0141\n",
      "Epoch 156/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.0142\n",
      "Epoch 157/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.0138\n",
      "Epoch 158/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.0141\n",
      "Epoch 159/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.0139\n",
      "Epoch 160/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.0141\n",
      "Epoch 161/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.0136\n",
      "Epoch 162/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.0140\n",
      "Epoch 163/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.0139\n",
      "Epoch 164/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.0138\n",
      "Epoch 165/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.0143\n",
      "Epoch 166/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.0139\n",
      "Epoch 167/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.0140\n",
      "Epoch 168/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.0138\n",
      "Epoch 169/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.0136\n",
      "Epoch 170/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.0139\n",
      "Epoch 171/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.0140\n",
      "Epoch 172/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.0138\n",
      "Epoch 173/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.0138\n",
      "Epoch 174/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.0139\n",
      "Epoch 175/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.0140\n",
      "Epoch 176/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.0139\n",
      "Epoch 177/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.0137\n",
      "Epoch 178/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.0134\n",
      "Epoch 179/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.0136\n",
      "Epoch 180/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.0140\n",
      "Epoch 181/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.0135\n",
      "Epoch 182/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.0136\n",
      "Epoch 183/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.0136\n",
      "Epoch 184/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.0135\n",
      "Epoch 185/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.0139\n",
      "Epoch 186/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.0136\n",
      "Epoch 187/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.0139\n",
      "Epoch 188/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.0139\n",
      "Epoch 189/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.0135\n",
      "Epoch 190/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.0134\n",
      "Epoch 191/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.0135\n",
      "Epoch 192/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.0135\n",
      "Epoch 193/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.0137\n",
      "Epoch 194/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.0135\n",
      "Epoch 195/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.0135\n",
      "Epoch 196/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.0136\n",
      "Epoch 197/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.0134\n",
      "Epoch 198/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.0134\n",
      "Epoch 199/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.0135\n",
      "Epoch 200/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.0134\n",
      "Epoch 201/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.0133\n",
      "Epoch 202/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.0134\n",
      "Epoch 203/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.0135\n",
      "Epoch 204/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.0135\n",
      "Epoch 205/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.0134\n",
      "Epoch 206/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.0131\n",
      "Epoch 207/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.0134\n",
      "Epoch 208/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.0136\n",
      "Epoch 209/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.0134\n",
      "Epoch 210/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.0131\n",
      "Epoch 211/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.0135\n",
      "Epoch 212/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.0135\n",
      "Epoch 213/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.0133\n",
      "Epoch 214/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.0133\n",
      "Epoch 215/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.0133\n",
      "Epoch 216/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.0134\n",
      "Epoch 217/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.0132\n",
      "Epoch 218/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.0133\n",
      "Epoch 219/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.0135\n",
      "Epoch 220/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.0133\n",
      "Epoch 221/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.0133\n",
      "Epoch 222/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.0130\n",
      "Epoch 223/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.0133\n",
      "Epoch 224/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.0132\n",
      "Epoch 225/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.0130\n",
      "Epoch 226/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.0133\n",
      "Epoch 227/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.0133\n",
      "Epoch 228/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.0132\n",
      "Epoch 229/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.0133\n",
      "Epoch 230/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.0130\n",
      "Epoch 231/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.0134\n",
      "Epoch 232/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.0131\n",
      "Epoch 233/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.0131\n",
      "Epoch 234/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.0131\n",
      "Epoch 235/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.0131\n",
      "Epoch 236/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.0130\n",
      "Epoch 237/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.0129\n",
      "Epoch 238/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.0131\n",
      "Epoch 239/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.0132\n",
      "Epoch 240/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.0129\n",
      "Epoch 241/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.0130\n",
      "Epoch 242/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.0130\n",
      "Epoch 243/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.0127\n",
      "Epoch 244/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.0127\n",
      "Epoch 245/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.0128\n",
      "Epoch 246/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.0131\n",
      "Epoch 247/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.0127\n",
      "Epoch 248/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.0127\n",
      "Epoch 249/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.0130\n",
      "Epoch 250/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.0132\n",
      "Epoch 251/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.0130\n",
      "Epoch 252/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.0129\n",
      "Epoch 253/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.0129\n",
      "Epoch 254/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.0128\n",
      "Epoch 255/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.0126\n",
      "Epoch 256/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.0127\n",
      "Epoch 257/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.0126\n",
      "Epoch 258/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.0127\n",
      "Epoch 259/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.0126\n",
      "Epoch 260/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.0128\n",
      "Epoch 261/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.0130\n",
      "Epoch 262/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.0127\n",
      "Epoch 263/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.0127\n",
      "Epoch 264/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.0127\n",
      "Epoch 265/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.0126\n",
      "Epoch 266/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.0127\n",
      "Epoch 267/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.0127\n",
      "Epoch 268/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.0125\n",
      "Epoch 269/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.0126\n",
      "Epoch 270/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.0124\n",
      "Epoch 271/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.0126\n",
      "Epoch 272/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.0125\n",
      "Epoch 273/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.0128\n",
      "Epoch 274/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.0126\n",
      "Epoch 275/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.0126\n",
      "Epoch 276/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.0127\n",
      "Epoch 277/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.0127\n",
      "Epoch 278/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.0127\n",
      "Epoch 279/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.0126\n",
      "Epoch 280/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.0127\n",
      "Epoch 281/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.0123\n",
      "Epoch 282/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.0123\n",
      "Epoch 283/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9228 - loss: 0.0124\n",
      "Epoch 284/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.0125\n",
      "Epoch 285/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.0126\n",
      "Epoch 286/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.0126\n",
      "Epoch 287/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.0122\n",
      "Epoch 288/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.0126\n",
      "Epoch 289/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.0125\n",
      "Epoch 290/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.0124\n",
      "Epoch 291/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.0125\n",
      "Epoch 292/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.0121\n",
      "Epoch 293/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.0122\n",
      "Epoch 294/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.0124\n",
      "Epoch 295/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.0122\n",
      "Epoch 296/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.0123\n",
      "Epoch 297/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.0125\n",
      "Epoch 298/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.0127\n",
      "Epoch 299/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.0122\n",
      "Epoch 300/300\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.0124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2e024115150>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lables = model(train_images)\n",
    "loss_function(train_labels, pred_lables)\n",
    "model.fit(train_images,\n",
    "          train_labels, \n",
    "          epochs=300, \n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the accuracy: 92.31%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
